{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"https://github.com/amalvarezme/AprendizajeMaquina/blob/main/7_TopicosAvanzados/Autoencoders/AutoencoderPCA.ipynb","timestamp":1708909669566}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"YDVkD7gM1YrH"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, losses, Model\n","from tensorflow.keras.datasets import mnist\n","import numpy as np\n","\n","# Load and prepare the MNIST dataset\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","scale = 0.4\n","x_train = x_train.astype('float32') / 255. + np.random.normal(scale=scale,size=x_train.shape)\n","x_test = x_test.astype('float32') / 255. + np.random.normal(scale=scale,size=x_test.shape)\n","\n","# create training, validation, and testing sets\n","x_val = x_train[50000:]\n","y_val = y_train[50000:]\n","x_train = x_train[:50000]\n","y_train = y_train[:50000]\n","x_train = x_train[..., tf.newaxis]\n","x_val = x_val[..., tf.newaxis]\n","x_test = x_test[..., tf.newaxis]\n","\n","print(x_train.shape,x_val.shape,x_test.shape,y_train.shape,y_val.shape,y_test.shape)"]},{"cell_type":"code","source":["y_train"],"metadata":{"id":"9czMRgQj5oHg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","#plot original images vs reconstructed images\n","def plot_mnist_autoencoder(x,xpred,cmap='gray',vmin=0,vmax=1):\n","  fig,ax = plt.subplots(2,x.shape[0],figsize=(8,1))\n","  for i,class_ in enumerate(range(x.shape[0])):\n","        ax[0,i].imshow(x[i],cmap=cmap,vmin=vmin,vmax=vmax)\n","        ax[0,i].set_xticks([])\n","        ax[0,i].set_yticks([])\n","\n","        ax[1,i].imshow(xpred[i],cmap=cmap,vmin=vmin,vmax=vmax)\n","        ax[1,i].set_xticks([])\n","        ax[1,i].set_yticks([])\n","  plt.show()\n","  return\n","\n","def plot_mnist_autoencoder2(x, xpred, y, y_pred, cmap='gray', vmin=0, vmax=1):\n","    # Número de imágenes a visualizar\n","    num_images = x.shape[0]\n","\n","    # Configura el espacio de visualización\n","    fig, ax = plt.subplots(2, num_images, figsize=(15,5))\n","\n","    # Visualiza cada par de imágenes original y reconstruida junto con sus etiquetas\n","    for i in range(num_images):\n","        # Imagen original\n","        ax[0, i].imshow(x[i], cmap=cmap, vmin=vmin, vmax=vmax)\n","        ax[0, i].set_xticks([])\n","        ax[0, i].set_yticks([])\n","        ax[0, i].set_xlabel(f\"y: {y[i]}\", fontsize=10)  # Muestra la etiqueta real debajo de la imagen\n","        ax[0, i].xaxis.set_label_position('top')\n","\n","        # Imagen reconstruida\n","        ax[1, i].imshow(xpred[i], cmap=cmap, vmin=vmin, vmax=vmax)\n","        ax[1, i].set_xticks([])\n","        ax[1, i].set_yticks([])\n","        ax[1, i].set_xlabel(f\"y_pred: {y_pred[i]}\", fontsize=10)  # Muestra la etiqueta predicha debajo de la imagen\n","        ax[1, i].xaxis.set_label_position('top')\n","\n","    plt.tight_layout()\n","    plt.show()\n","    return\n","plot_mnist_autoencoder2(x_train[:15],x_train[:15],y_train,y_train)\n","\n","from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n","\n","#plot images on latent space\n","def plot_mnist_2d(Z,y,images,img_w=28,img_h=28,zoom=0.5,cmap='jet'):\n","    fig, ax = plt.subplots(figsize=(5,5))\n","    plt.axis('off')\n","    for i in range(Z.shape[0]):\n","        #print('img',i+1,'/',Z.shape[0])\n","        image = images[i].reshape((img_w, img_h))\n","        im = OffsetImage(image, zoom=zoom,cmap=cmap)\n","        ab = AnnotationBbox(im, (Z[i,0], Z[i,1]), xycoords='data', frameon=False)\n","        ax.add_artist(ab)\n","        ax.update_datalim([(Z[i,0], Z[i,1])])\n","        ax.autoscale()\n","    plt.show()"],"metadata":{"id":"C2GUMmcM57Wg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.constraints import Constraint\n","class OrthogonalConstraint(Constraint):\n","    def __call__(self, w):\n","        a, u, _ = tf.linalg.svd(w, full_matrices=False)\n","        return u\n","class DenseTransposeLayer(layers.Layer):\n","    def __init__(self, units, factor_o=0.1,activation=None, **kwargs):\n","        super(DenseTransposeLayer, self).__init__(**kwargs)\n","        self.units = units\n","        self.factor_o = factor_o\n","        self.activation = tf.keras.activations.get(activation)\n","\n","    def build(self, input_shape):\n","        self.w = self.add_weight(\n","            shape=(input_shape, self.units),\n","            initializer=\"random_normal\",\n","            trainable=True,regularizer=tf.keras.regularizers.OrthogonalRegularizer(factor=self.factor_o),\n","            constraint=OrthogonalConstraint()\n","        )\n","        #self.b1 = self.add_weight(\n","        #    shape=(self.units,), initializer=\"zeros\", trainable=True)\n","        #self.b2 = self.add_weight(\n","        #    shape=(input_shape[-1],), initializer=\"zeros\", trainable=True)\n","\n","        super(DenseTransposeLayer, self).build(input_shape)\n","\n","    def call(self, inputs):\n","        x1 = tf.matmul(inputs, self.w)  # Si quieres agregar el sesgo, añade + self.b1\n","        if self.activation is not None:\n","            x1 = self.activation(x1)\n","        x2 = tf.matmul(x1, tf.transpose(self.w))  # Si quieres agregar el segundo sesgo, añade + self.b2\n","        return x2, x1  # Devuelve ambos valores"],"metadata":{"id":"-9Vj-G66hlV-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PCAutoencoder(Model):\n","    def __init__(self, encoding_dim, num_classes, factor_o=0.1):\n","        super(PCAutoencoder, self).__init__()\n","        self.encoding_dim = encoding_dim\n","        self.num_classes = num_classes\n","        self.factor_o = factor_o\n","        # Encoder layers\n","        self.encoder_input_layer = layers.Flatten()\n","        self.encoder_decoder_transpose = DenseTransposeLayer(self.encoding_dim, factor_o=self.factor_o, activation='linear')\n","\n","        # Clasificador con múltiples capas\n","        self.classifier_layers = [\n","            layers.Dense(128, activation='relu'),  # Primera capa densa\n","            layers.Dropout(0.5),  # Dropout para regularización\n","            layers.Dense(256, activation='relu'),   # Segunda capa densa\n","            layers.Dense(num_classes, activation='softmax')  # Capa de salida\n","        ]\n","\n","        # Decoder layers will be initialized in build()\n","        self.decoder_output_layer = None\n","\n","    def build(self, input_shape):\n","        # Initialize decoder layers\n","        self.encoder_decoder_transpose.build(input_shape[1]*input_shape[2])\n","        self.decoder_output_layer = layers.Reshape(input_shape[1:])\n","        super().build(input_shape)\n","\n","    def call(self, inputs):\n","        x = self.encoder_input_layer(inputs)\n","        out,encoded = self.encoder_decoder_transpose(x)\n","        encoded\n","        # Pasar los datos codificados a través de las capas del clasificador\n","        for layer in self.classifier_layers:\n","            encoded = layer(encoded)\n","        classification = encoded  # La última capa modifica 'encoded' para ser la salida de clasificación\n","        decoded = self.decoder_output_layer(out)\n","        return decoded, classification\n"],"metadata":{"id":"ow4as9Cpum3x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Instantiate the autoencoder\n","encoding_dim = 64\n","input_shape = (None, 28, 28, 1)\n","factor_o = 0.1\n","num_classes = 10\n","optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.1)\n","pcautoencoder = PCAutoencoder(encoding_dim, num_classes, factor_o=factor_o)\n","\n","pcautoencoder.build(input_shape)\n","# Compila el modelo con funciones de pérdida específicas para cada salida y un optimizador\n","pcautoencoder.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),  # Ajusta el learning rate si es necesario\n","    loss={'decoded': 'mse', 'classification': 'sparse_categorical_crossentropy'},  # Asume 'decoded' y 'classification' son los nombres de las salidas\n","    metrics={'decoded': 'mse', 'classification': 'accuracy'}\n",")\n","pcautoencoder.summary()"],"metadata":{"id":"lejCsibaCTIm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the loss object and the optimizer\n","tf.keras.backend.clear_session()\n","optimizer = tf.keras.optimizers.Adam()\n","loss_object_reconstruction = tf.keras.losses.MeanSquaredError()\n","loss_object_classification = tf.keras.losses.SparseCategoricalCrossentropy()\n","\n","# Definir medidas adicionales para la pérdida de clasificación\n","train_classification_loss = tf.keras.metrics.Mean(name='train_classification_loss')\n","test_classification_loss = tf.keras.metrics.Mean(name='val_classification_loss')\n","# Define measures to track loss\n","train_loss = tf.keras.metrics.Mean(name='train_loss')\n","test_loss = tf.keras.metrics.Mean(name='val_loss')\n","@tf.function\n","def train_step(images, labels):\n","    with tf.GradientTape() as tape:\n","        reconstructed, predictions = pcautoencoder(images, training=True)\n","        reconstruction_loss = loss_object_reconstruction(images, reconstructed)\n","        classification_loss = loss_object_classification(labels, predictions)\n","        a=0.9\n","        b=1-a\n","        total_loss = a*reconstruction_loss + b*classification_loss  # Ajusta esta línea según necesites ponderar las pérdidas\n","    gradients = tape.gradient(total_loss, pcautoencoder.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, pcautoencoder.trainable_variables))\n","    train_loss(a*reconstruction_loss)\n","    train_classification_loss(b*classification_loss)\n","\n","@tf.function\n","def test_step(images, labels):\n","    reconstructed, predictions = pcautoencoder(images, training=False)\n","    a=0.9\n","    b=1-a\n","    t_reconstruction_loss = loss_object_reconstruction(images, reconstructed)\n","    t_classification_loss = loss_object_classification(labels, predictions)\n","    test_loss(a*t_reconstruction_loss)\n","    test_classification_loss(b*t_classification_loss)\n","\n","epochs = 20\n","batch_size = 64\n","train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(buffer_size=1024).batch(batch_size)\n","val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val)).shuffle(buffer_size=1024).batch(batch_size)\n","\n","for epoch in range(epochs):\n","    # Reset the metrics at the start of the epoch\n","    train_loss.reset_states()\n","    test_loss.reset_states()\n","    train_classification_loss.reset_states()\n","    test_classification_loss.reset_states()\n","\n","    for images, labels in train_dataset:\n","        train_step(images, labels)\n","\n","    for val_images, val_labels in val_dataset:\n","        test_step(val_images, val_labels)\n","\n","    print(f'Epoch {epoch + 1}, '\n","          f'Loss: {train_loss.result()}, '\n","          f'Classification Loss: {train_classification_loss.result()}, '\n","          f'Test Loss: {test_loss.result()}, '\n","          f'Test Classification Loss: {test_classification_loss.result()}')\n","\n","    if (epoch+1) % 5 == 0:\n","        val_reconstructed, val_label_re = pcautoencoder(val_images, training=False)  # Ignora la salida de clasificación\n","        print(val_reconstructed.shape)\n","        # Asegúrate de que plot_mnist_autoencoder pueda manejar esta salida correctamente\n","        plot_mnist_autoencoder2(val_images, val_reconstructed,val_labels,np.argmax(val_label_re.numpy(),axis=1))"],"metadata":{"id":"TKsXoIieC4uN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#compute inner product among basis\n","o_ = tf.linalg.matmul(pcautoencoder.layers[1].get_weights()[0],pcautoencoder.layers[1].get_weights()[0],transpose_a=True)\n","plt.pcolormesh(o_.numpy())\n","plt.colorbar()\n","plt.ylim([64,0])\n","plt.show()"],"metadata":{"id":"DVmOpwNUNQ2Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.pcolormesh(pcautoencoder.layers[1].get_weights()[0])\n","plt.colorbar()\n","plt.show()"],"metadata":{"id":"M0Nq1yamN0VR"},"execution_count":null,"outputs":[]}]}